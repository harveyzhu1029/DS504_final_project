# DS504_final_project

I used two datasets for this project. The first one is the 2GB trajectory data of a taxi company in GUIYANG city, which is used for testing the performance of Phoenix and ElasticSearch. For the bussiness secret, it could not be uploaded in the public resources. But I do show the screenshot of this dataset in my PPT and explain every attributes of the data.

The second dataset is nearly 52GB trajectory data after map-matching. I used this dataset to test the performance of ElasticSearch in real distributed system with large data. Since the dataset is extremly large, I extract like 1GB data out of the original dataset and uploaded it on the Google drive. The road numbers in this dataset are after data masking, link for this dataset: https://drive.google.com/open?id=1IUn1SR8-a_eDCoMW4LYxEd6F5-rcvAua

Since the main goal for my project is to discover a new way to store big trajectory data, most of work and codes are about the deployment of all kinds of big data tools and its corresponding environment. Therefore, I also uploaded two documents about how to deploy the Phoenix and ElasticSearch.
